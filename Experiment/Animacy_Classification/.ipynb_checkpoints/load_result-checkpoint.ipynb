{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import cPickle\n",
    "file = 'conll_test.dat'\n",
    "# data = cPickle.load(open(file,'rb'))\n",
    "temp_data = cPickle.load(open('temp.dat','rb'))\n",
    "real_result = cPickle.load(open('y_test.dat','rb'))\n",
    "\n",
    "# 准备所有的词语\n",
    "with open('./data/test/test_human.txt','r') as hdl:\n",
    "    human_words = set([i.strip('\\r\\n').decode('utf-8') for i in hdl.readlines()])\n",
    "with open('./data/test/test_non_human.txt','r') as hdl:\n",
    "    non_human_words = set([i.strip('\\r\\n').decode('utf-8') for i in hdl.readlines()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "此\n",
      "牢\n",
      "生\n",
      "权\n",
      "钱\n",
      "党\n",
      "书\n"
     ]
    }
   ],
   "source": [
    "for i in non_human_words:\n",
    "    if len(i) <= 1:\n",
    "        print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "711 711\n",
      "746 746\n",
      "-------------\n",
      "504 503\n",
      "957 954\n"
     ]
    }
   ],
   "source": [
    "res_human = []\n",
    "res_non_human = []\n",
    "t = 0\n",
    "for k,v in temp_data:\n",
    "    t += 1\n",
    "#     print k,'|',v,type(v)\n",
    "    if float(v) == 0.0:\n",
    "        res_human.append(k)\n",
    "    elif float(v) == 1.0:\n",
    "        res_non_human.append(k)\n",
    "    else:\n",
    "        print t, k   \n",
    "print len(human_words),len(set(human_words))\n",
    "print len(non_human_words), len(set(non_human_words))\n",
    "print '-------------'\n",
    "print len(res_human), len(set(res_human))\n",
    "print len(res_non_human), len(set(res_non_human))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "普京总统 1.0\n",
      "哈洛德 1.0\n",
      "谈判双方 0.0\n",
      "一些特定的一些人群，啊就是可能有些人 1.0\n",
      "张梅良会长 0.0\n",
      "律师 0.0\n",
      "这个比我们年龄大一倍的男人 0.0\n",
      "丽莎·玛莉·普莱斯利 1.0\n",
      "９·２１大地震当中涉嫌侵吞公款的前新竹市议长郑成光 1.0\n",
      "汤姆·汉克斯 1.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print temp_data[i][0],temp_data[i][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128 337\n",
      "0.68085106383\n"
     ]
    }
   ],
   "source": [
    "err1 = []\n",
    "err2 = []\n",
    "for word, tag in temp_data:\n",
    "    if tag == 0.0 and word in non_human_words:# and word not in human_words:\n",
    "        err1.append(word)\n",
    "    elif tag == 1.0 and word in human_words:# and word not in non_human_words:\n",
    "        err2.append(word)\n",
    "\n",
    "# err1 = set(human_words) - set(res_human)\n",
    "# err2 = set(non_human_words) - set(res_non_human)\n",
    "print len(err1),len(err2)\n",
    "print 1 - (len(err1) + len(err2)) / (len(set(human_words)) + len(set(non_human_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('error1.txt', 'w') as hdl:\n",
    "    hdl.write('错分成人类的词语\\n')\n",
    "    for w in err1:\n",
    "        hdl.write(w.encode('utf-8') + '\\n')\n",
    "with open('error2.txt', 'w') as hdl:\n",
    "    hdl.write('错分成非人类的词语\\n')\n",
    "    for w in err2:\n",
    "        hdl.write(w.encode('utf-8') + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_non_human.txt','w') as hdl:\n",
    "    for i in set(non_human_words):\n",
    "        hdl.write(i.encode('utf-8') + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
